{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\"><a title=\"Data Science-AIMS-Cmr-2021-22\">Neural Networks for Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"green\"> Learning outcomes:\n",
    "\n",
    "* Implementing a neural network for feature based classification\n",
    "\n",
    "* Using the ```CategoricalCrossentropy``` loss\n",
    "\n",
    "* How to use ```EarlyStopping``` to prevent overfitting.\n",
    "\n",
    "* Uses the build in softmax function\n",
    "\n",
    "* Obtaining confusion matrix\n",
    "\n",
    "## <font color=\"green\">Data information:\n",
    "\n",
    "* Features: 4 real-valued features\n",
    "\n",
    "* Output: 3-class target represented by strings\n",
    "\n",
    "## <font color=\"green\">Tasks for participants (boolean)?\n",
    "\n",
    "* No, follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Odaw35SnUk6H"
   },
   "source": [
    "## Various Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8M1nH2IzI7x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import pandas\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import metrics\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1VWGvj2zI8B"
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "This data sets consists of 3 different types of irisesâ€™ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray\n",
    "\n",
    "The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "\n",
    "The dataset is obtained from scikit learn https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wae_HjknzI8E"
   },
   "outputs": [],
   "source": [
    "iris_data = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ6eY3coY_QZ"
   },
   "source": [
    "The load_iris() returns a 'sklearn.utils.Bunch' which is kind of like a Python dictionary with the following keys. In our case we don't need all of that information, we really just need the actual data (i.e. features and class variables). \n",
    "\n",
    "Bunch objects are sometimes used as an output for functions and methods. They extend dictionaries by enabling values to be accessed by key, bunch[\"value_key\"], or by an attribute, bunch.value_key.\n",
    "\n",
    "If you are interested in the Bunch object, here is the API https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf-ucxEEeEFU",
    "outputId": "c31bcafe-3911-434d-a412-e46a60d3c5fa"
   },
   "outputs": [],
   "source": [
    "type(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZURN_IUhY8lA",
    "outputId": "6204d61d-5b97-4d7c-c903-c714eef496e7"
   },
   "outputs": [],
   "source": [
    "iris_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viKnwTKXZN3R"
   },
   "source": [
    "Nonetheless let's take a look at everything that we get when we call the iris_data() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPMKxNaNw8af",
    "outputId": "5dbda0f3-e736-47e0-9e6a-4028b0ea79fb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iris_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoQte1UJZT4l"
   },
   "source": [
    "Now let's extract what we really want, the data, which is stored in the 'data' key in thie iris_data dictionary. Calling the data key will provide us with the features in this case. Remember, this dataset is formatted in this particular way. Not every dataset will be stored in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6whopOpnZT9B"
   },
   "outputs": [],
   "source": [
    "dataset = iris_data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nP7i2EOwyZVa"
   },
   "source": [
    "## View the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pM9-iHobzI8L",
    "outputId": "f076cc38-652e-4010-87cf-54f4a9354fb5"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfeDy2AP1p2T"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "You might already know that neural networks perform best when the features are scaled/normalised instead of being on different scales. Let's take a look and check if the features are on similar scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "qD6qAWBWZ01b",
    "outputId": "322f34ff-0dc5-4ff2-a142-fcd9540c9c04"
   },
   "outputs": [],
   "source": [
    "plt.hist(dataset[:,0])\n",
    "plt.title('Feature 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7p5uS7iccSr",
    "outputId": "ddf6ebe7-3663-4345-dba7-c9da01c068b4"
   },
   "outputs": [],
   "source": [
    "print ('mean feature 0:',np.mean(dataset[:,0]))\n",
    "print ('sdev feature 0:',np.std(dataset[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "yDIBsadwbLUo",
    "outputId": "1e24781b-1d77-4e58-8ae6-ee41840e3625"
   },
   "outputs": [],
   "source": [
    "plt.hist(dataset[:,1])\n",
    "plt.title('Feature 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_m_6Oyl-cr-k",
    "outputId": "380a01d7-45ef-4bd8-9c3e-c4600be6c3e5"
   },
   "outputs": [],
   "source": [
    "print ('mean feature 1:',np.mean(dataset[:,1]))\n",
    "print ('sdev feature 1:',np.std(dataset[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "O67lFO1UbLXc",
    "outputId": "01c60546-0f01-467c-dbab-a6761ac4af83"
   },
   "outputs": [],
   "source": [
    "plt.hist(dataset[:,2])\n",
    "plt.title('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44mkcVhict1M",
    "outputId": "7e5aa5b5-04ef-4cd5-92b5-44a203605444"
   },
   "outputs": [],
   "source": [
    "print ('mean feature 2:',np.mean(dataset[:,2]))\n",
    "print ('sdev feature 2:',np.std(dataset[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "EejB2t52bMCN",
    "outputId": "85aefab7-42d1-4660-c49d-b3835d4d5184"
   },
   "outputs": [],
   "source": [
    "plt.hist(dataset[:,3])\n",
    "plt.title('Feature 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6JavQjIocwJg",
    "outputId": "425c9d32-a87a-4cd1-a58e-c5e3ee1f8dfd"
   },
   "outputs": [],
   "source": [
    "print ('mean feature 3:',np.mean(dataset[:,3]))\n",
    "print ('sdev feature 3:',np.std(dataset[:,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSc-zD35dIvf"
   },
   "source": [
    "## Now let's scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a8npr1R1p8q"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(dataset)\n",
    "scaled_dataset = scaler.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "POpe1yfbbmY6",
    "outputId": "c6bffa6b-0a04-41c9-ba33-41ff8bfcb59c"
   },
   "outputs": [],
   "source": [
    "plt.hist(scaled_dataset[:,0])\n",
    "plt.title('Feature 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRx3qER8cM8q",
    "outputId": "c549f0bb-0278-437b-d403-433aeab6919b"
   },
   "outputs": [],
   "source": [
    "print ('mean feature 0:',np.mean(scaled_dataset[:,0]))\n",
    "print ('sdev feature 0:',np.std(scaled_dataset[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "6sIQCY8SbmZB",
    "outputId": "ca4f5b8b-22f5-4d61-9fb3-1459a28562f5"
   },
   "outputs": [],
   "source": [
    "plt.hist(scaled_dataset[:,1])\n",
    "plt.title('Feature 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hN6GLVSKcUKi",
    "outputId": "d6f875c9-e63e-49e3-c7a2-a9cc264b8949"
   },
   "outputs": [],
   "source": [
    "print ('mean feature 1:',np.mean(scaled_dataset[:,1]))\n",
    "print ('sdev feature 1:',np.std(scaled_dataset[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "1HLslloubmZG",
    "outputId": "58062693-21af-4be3-b17a-d6cd4135f677"
   },
   "outputs": [],
   "source": [
    "plt.hist(scaled_dataset[:,2])\n",
    "plt.title('Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFu9vnEPc4i_",
    "outputId": "c9a6e341-90c2-472b-f814-e6d0156faffb"
   },
   "outputs": [],
   "source": [
    "print ('mean feature 2:',np.mean(scaled_dataset[:,2]))\n",
    "print ('sdev feature 2:',np.std(scaled_dataset[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "FgTEruT2bmZM",
    "outputId": "b1f1b538-aa58-4a43-fd11-fecd27125859"
   },
   "outputs": [],
   "source": [
    "plt.hist(scaled_dataset[:,3])\n",
    "plt.title('Feature 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QZoFrCUcW1d",
    "outputId": "e9b817a0-6f4e-41eb-c4fe-aa136218972f"
   },
   "outputs": [],
   "source": [
    "print ('mean feature 3:',np.mean(scaled_dataset[:,3]))\n",
    "print ('sdev feature 3:',np.std(scaled_dataset[:,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5OWXzlh2QfI"
   },
   "source": [
    "## Check the shape of the data\n",
    "\n",
    "It is generally a good idea to check your data once you conduct some manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJRYNPCb2DKh",
    "outputId": "7069a7d8-2784-4746-ef2c-f911fbba6fdc"
   },
   "outputs": [],
   "source": [
    "scaled_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvgD4qrRdv6S"
   },
   "source": [
    "Okay so we have 150 examples and 4 features. Next we need to create our X and Y variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkjvHAwIzI8d"
   },
   "source": [
    "## Split the data into features and the class values\n",
    "\n",
    "The dataset above (when we loaded it) had another key in the 'Bunch' called 'target'. So we can call that key and get the values of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpXOcpfNzI8f"
   },
   "outputs": [],
   "source": [
    "X = scaled_dataset\n",
    "Y = iris_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veL9WiQKeg11"
   },
   "source": [
    "Let's take a look at the unique values in the Y target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wXGGVScBeg7d",
    "outputId": "8b9ac969-8816-4f2d-ce79-e8e71911c0c3"
   },
   "outputs": [],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YISLUOeIerCn"
   },
   "source": [
    "Okay so we cannot leave the targets as integer values. We don't want a neural network to assume that 2 is greater than 1 or that the targets have ordinal meaning (1 > 0, 2> 1 etc...). \n",
    "\n",
    "We also cannot train a neural network on categorical data represented as text. For example in this example, [0,1,2] corresponds to ['setosa', 'versicolor', 'virginica']. If instead of the numbers, the Y variable had strings of classes (e.g. Y = ['setosa', 'setosa', 'versicolor' ...  , 'versicolor'])\n",
    "\n",
    "To deal with this, we can convert out targets into one-hot encoded vectors. Keras has a function called 'np_utils.to_categorical()' which helps us achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IN7hHj3Afac"
   },
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "maplMBltAfh-"
   },
   "outputs": [],
   "source": [
    "Y = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-1lUjmxf3Dg"
   },
   "source": [
    "Let's take a look at the first 5 examples after applying the encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-q0xQbXfvfY",
    "outputId": "00beb4bf-6de6-446e-f08c-51d233931e47"
   },
   "outputs": [],
   "source": [
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0n53sxnf66W"
   },
   "source": [
    "Okay so clearly the targets have been converted into their one-hot encoded vectors! Great, now let's double check the shapes of X and Y before creatining our training, validation and test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiV6vedSyeKO"
   },
   "source": [
    "## Check the shapes of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "reP8T4fuzI8k",
    "outputId": "dd00dab3-327b-490c-abc6-6aba8d6582ae"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IThy90cczI8r",
    "outputId": "ed4b5f78-114c-413a-bb0e-503d08e3a58c"
   },
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENDcb5y1zI85"
   },
   "source": [
    "## Split the data into training and test data\n",
    "\n",
    "After inspection, the shapes look correct and the target values look correct too (dimensions of 3 since we have 3 unique classes). Once we have our data into X (features) and Y (class) variables we can proceed to the next step which is to create training and testing data. This is similar to the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNRXxIANzI86"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "248QHMZlzI9d"
   },
   "source": [
    "## Create a neural network model\n",
    "\n",
    "Some points to keep in mind everytime you define a model:\n",
    "\n",
    "* Remember to specify and intput dimension for the first layer (this is always  the case for the first layer only)\n",
    "* You will have to define a model architecture, how many layers, how many units etc...\n",
    "* You will have to compile the model, specify a loss function and optimiser. The metric is not used in any calculation, it is an easy-to-use evaluation metric for us humans to monitor the model. API documentation on metrics is here: https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
    "\n",
    "We specify the loss function as a Tensorflow.keras.losses object, in this case categorical cross entropy loss. The API documentation is here: https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy \n",
    "\n",
    "In the examples so far we have been calling activation functions by their pre-defined names such as 'linear', 'relu' and 'softmax'. But other activation functions exist. The formal document is available, here is an example for ReLU https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu and you can see that we can use it as: tf.keras.activations.relu we can import it and then use it as follows:\n",
    "\n",
    "```from tensorflow.keras.activations import relu```\n",
    "\n",
    "and then we would use it within a layer as follows\n",
    "\n",
    "```model.add(Dense(2, input_dim=4, activation=relu, kernel_initializer = initializer))```\n",
    "\n",
    "Notice in the above example we wrote ```activation=relu``` instead of ```activation='relu'```. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJWPXPcfzI9f"
   },
   "outputs": [],
   "source": [
    "def baseline():\n",
    "  \n",
    "    # Seeting a seed so we can reproduce the results\n",
    "    tf.random.set_seed(137)\n",
    "\n",
    "    # Define the initialisation method\n",
    "    initializer = RandomNormal(mean = 0.0, stddev=0.01)\n",
    "\n",
    "    # create a squential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # add one fully connected layer\n",
    "    model.add(Dense(2, input_dim=4, activation='relu', kernel_initializer = initializer))\n",
    "\n",
    "    # add one fully connected output layer with a softmax activation\n",
    "    model.add(Dense(3, activation='softmax', kernel_initializer = initializer))\n",
    "\n",
    "    # Define the optimiser\n",
    "    optimiser = Adam(learning_rate=0.001)\n",
    "\n",
    "    # Define the loss function\n",
    "    loss = CategoricalCrossentropy()\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimiser, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJ8KXYqYzI9k"
   },
   "source": [
    "## Initialise the model\n",
    "\n",
    "To initialise the model, we call our Python function which contains the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUjCbeYxzI9l"
   },
   "outputs": [],
   "source": [
    "model = baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyiaFBhbzI9p"
   },
   "source": [
    "## Determine the number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbOE34EezI9q",
    "outputId": "959e6160-6a0a-4ae9-cc2e-1076e34f53ee"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ht6sxL85iCVC"
   },
   "source": [
    "We can also view the model by plotting it. It gives a different perspective if you prefer this view. To do this we use the plot_model() function.\n",
    "\n",
    "API documentation for the plot_model() function https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model?hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "78a2zQoBiCaD",
    "outputId": "946f0a6f-7ae0-410c-db6a-771eb353a388"
   },
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxBBOszLm0HO"
   },
   "source": [
    "Let's add something new.\n",
    "\n",
    "Sometimes when we train models we can end up in situations where the network overfits and only gets worse. One way to handle this is to stop training once the validation loss does not improve over a certain number of epochs. Tensorflow has something called 'EarlyStopping' which does exactly that. Namely, it will stop training when a monitored metric has stopped improving. API: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping?hl=en\n",
    "\n",
    "In this example, we can monitor the validation accuracy. We want the validation loss to increase so we tell it that the 'mode' is to keep an eye if the validation accuracy is increasing. Formally, \"in min mode, training will stop when the quantity monitored has stopped decreasing\" The converse for max.\n",
    "\n",
    "We also specify a patience arguement. Formally, \"number of epochs with no improvement after which training will be stopped\". In our example, we will wait for 10 epochs.\n",
    "\n",
    "Here is the code to create this and then we need to add it to our fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0PURx6fm0Q8"
   },
   "outputs": [],
   "source": [
    "stopping = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUPUuRN0zI9w"
   },
   "source": [
    "## Fit the model\n",
    "\n",
    "Now that we have the training, validation and testing features and targets we can start training the network. To do this, we make use of the .fit() function like in the previous notebook. \n",
    "\n",
    "Here we add our callback which we created above 'stopping'. A callback is formally defined as \"utilities called at certain points during model training.\" We specify them in an array as we can add multiple callsbacks. In this example we only have one. In this example I specify a high number of epochs, let's see what happens, will it run for 400 epochs or stop before that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VACKCprNzI9y",
    "outputId": "df9bae68-86fe-4229-b125-24470ad3d4bc"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs = 400, callbacks=[stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xP-Cv2PXzI-E"
   },
   "source": [
    "## Plot the loss over the epochs\n",
    "\n",
    "Keep an eye out for over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "203wHuoUmT2E",
    "outputId": "ce277d56-0d06-411e-e59f-8cb0412d674b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss', linestyle='dashed')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Cross entropy loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "rb8PjGLBpYMh",
    "outputId": "8436451b-f864-487b-b172-ab502a82804a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy', linestyle='dashed')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l85BylX5zI93"
   },
   "source": [
    "## Predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBpk0OtRzI95"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-d6T3yCEA9D"
   },
   "source": [
    "## View predictions\n",
    "\n",
    "The predictions in this example are different to the previous notebooks. In this example the output is softmax outputs. Note the performance is pretty bad. The model provided above is not necessarily the best model :) Here we display the predictions on the first 5 testing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIZzxdWxEBE2",
    "outputId": "074cd5a0-e3c5-4e80-a19f-d4e5a8d307a8"
   },
   "outputs": [],
   "source": [
    "prediction[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJJbCzFxEDLx"
   },
   "source": [
    "## Predict classes (instead of softmax output)\n",
    "\n",
    "Here we use np.argmax() on the predictions to get the corresponding class (i.e. not the softmax but the iteger representations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFp91RkdEDSX"
   },
   "outputs": [],
   "source": [
    "prediction_classes = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlHWbAEwtV8c"
   },
   "source": [
    "Let's take a look at the predictions for the first 10 testing points and compare them to the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdIZKOZmEQfA",
    "outputId": "d22e27d9-0a91-4d7a-b28f-3919376c86c2"
   },
   "outputs": [],
   "source": [
    "prediction_classes[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7cJA4jWtkY7"
   },
   "source": [
    "Y_test is currently in one-hot encoded vector form. We can use the np.argmax() function to convert the vectors back into integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDl6QROptbUE",
    "outputId": "e5562e32-d998-4b1a-9e43-d82366dd3109"
   },
   "outputs": [],
   "source": [
    "np.argmax(Y_test,axis=1)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eHpGjh1zI9-"
   },
   "source": [
    "## Compute the confusion matrix\n",
    "\n",
    "Scikit learn has a class called confusion_matrix API: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion#sklearn.metrics.confusion_matrix which can compute the confusion matrix for us. This won't work on softmax output so we need to apply ```np.argmax()```. We have already done this for the model predictions. We imported this at the very top of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtqoZ6OuzI9_",
    "outputId": "081c148f-6de3-4215-fe9b-289e543f1e7b"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(np.argmax(Y_test,1), prediction_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OyzzA6HEaBh"
   },
   "source": [
    "## Compute the accuracy\n",
    "\n",
    "Scikit learn has a class called accuracy_score, API: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score which can compute multiclass/binary class accuracy. We imported this at the top of the script. Again, it does not work on softmax values.\n",
    "\n",
    "Accuracy is suitable in this example but for some examples one might want to consider different performance metrics. Additional options are available, take a look here: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTgIAAHIEaH2",
    "outputId": "54cfe2ec-c3a0-4cee-80f0-468338878599"
   },
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(Y_test,1), prediction_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vcc_SPx05hvi"
   },
   "source": [
    "# Task\n",
    "\n",
    "Try to improve the model accuracy by modifying the network. \n",
    "\n",
    "* You could try adding more layers, using different activation functions or \n",
    "\n",
    "* changing the number of units in each fully connected layer. \n",
    "\n",
    "The particular network I provided here was deliberately not optimal and thus the performance can definitely be improved :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sgSDDqE2uXx"
   },
   "source": [
    "# References:\n",
    "\n",
    "* This notebook was adpated from Dr. Emmanuel Dufourq,  2021 Gene Golub SIAM Summer School "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SIAM2021 NN Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
