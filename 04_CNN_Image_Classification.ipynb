{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNC6xKJiwxHU"
   },
   "source": [
    "<h1 style=\"text-align: center;\"><a title=\"Data Science-AIMS-Cmr-2021-22\">Convolutional Neural Networks for Image classification </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs3Vxo5dmP7j"
   },
   "source": [
    "\n",
    "\n",
    "***NOTE***\n",
    "\n",
    "<font color=\"red\">**Be sure to use hardware acceleration to use the GPU. Click on `Runtime`, change `runtime type`, and select `GPU` for the *hardware accelerator* option. Try to limit your time with the GPU. Terminate the session when possible due to limitations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W--Tn2TNfUQc"
   },
   "source": [
    "## <font color=\"green\"> Learning outcomes:\n",
    "\n",
    "* learn how implement CNNs\n",
    "\n",
    "* learn about ```Conv2D, MaxPool2D, Flatten, Dropout```\n",
    "\n",
    "* learn how to implement ```ModelCheckpoint``` and view them in the file system\n",
    "\n",
    "* learn how to convert softmax output into class predictions\n",
    "\n",
    "## <font color=\"green\">Data information:\n",
    "\n",
    "* Features: (28x28) images\n",
    "\n",
    "* Output: 10 classes represented by integers\n",
    "\n",
    "## <font color=\"green\">Tasks for participants (boolean)?\n",
    "\n",
    "* Yes, at the end (try avoid copy/pasting code, rather write it out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpvo-bqTmP7m"
   },
   "source": [
    "## Imports first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3573,
     "status": "ok",
     "timestamp": 1674731381011,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "nvCXvXq5mP7p"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1GTR35cmP7v"
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "We will use the FashionMNIST dataset. Documentation https://www.tensorflow.org/datasets/catalog/fashion_mnist\n",
    "\n",
    "By the way, there are a ton of datasets already available to you from Tensorflow, check them out here: https://www.tensorflow.org/datasets/catalog/overview\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
    "\n",
    "Note that the data has already been split into training and testing for us, phew! What's next though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4192,
     "status": "ok",
     "timestamp": 1674731400161,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "uQ_KjFJomP7x",
    "outputId": "49048708-5f8e-4ea6-cdb3-8d3b15c836f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-Lw_bPQKQFX"
   },
   "source": [
    "## View the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 673,
     "status": "ok",
     "timestamp": 1674731415875,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "ueyWl-aUmP72",
    "outputId": "6e901bb9-1756-4e62-8b45-a9b95b62d9f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1674731577190,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "3bsoluyzBOYR",
    "outputId": "c62640f2-e26d-42ac-a30c-f538799f60f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape :  (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z51sdOntmP78"
   },
   "source": [
    "## Find the unique numbers from the train labels\n",
    "\n",
    "From what we see below, we don't need to worry about label encoding as all the classes are integer values from 0 to 9 with no gaps between the values. Given that we have 10 classes, what does this tell us about the last layer in our network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1674731610180,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "o29O_gUTmP79",
    "outputId": "855ffaa2-adc0-4891-894c-b31a9bda1932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(Y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMMjLgbimP8B"
   },
   "source": [
    "## Plot some of the data\n",
    "\n",
    "You can change the value of ```data_point``` to explore different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1674731783657,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "qQpW4rajmP8C",
    "outputId": "fa57b089-199c-4e77-8d44-be2f620ca0b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth : 6')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_point = 40\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    " \n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[data_point,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(Y_train[data_point]))\n",
    " \n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_test[data_point,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(Y_test[data_point]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA_mGK_NVHwn"
   },
   "source": [
    "## Reshape needed\n",
    "\n",
    "Tensorflow wants to know the depth of an image. API https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "For CNNS, Tensorflow wants the format of the data as follows: [batches, rows, columns, depth]. \n",
    "\n",
    "In this case the colour channel/depth of the images is 1. Currently the shape is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1674731833870,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "TBbn1qONB0M8",
    "outputId": "457b09da-c516-461c-8a55-d1240dd057da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a55ZpEbCB6kQ"
   },
   "source": [
    "We have a width of 28 and a height of 28 but no depth. So we can reshape it to include a value of one using the Numpy reshape function. Documentation https://numpy.org/doc/stable/reference/generated/numpy.reshape.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1674731836725,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "D8HTp2YHVH4_"
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lQP7CElWVfe"
   },
   "source": [
    "## View the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1674731840936,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "5QKOvMPaWVfh",
    "outputId": "ec71cfef-de97-427e-bc85-8daca14da283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28, 1) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1674731909976,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "zzGxSUONCRb2",
    "outputId": "1f3c7204-590f-4890-c0a1-1ed8e9ecda46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape :  (10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyXyan4NCnVL"
   },
   "source": [
    "## Take a look at a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1674731912439,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "YNkeCMoUmP8Y",
    "outputId": "5bee5ae1-9b2d-49ec-aa72-2415dec12210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 13],\n",
       "        [ 73],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  4],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  1],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  3],\n",
       "        [  0],\n",
       "        [ 36],\n",
       "        [136],\n",
       "        [127],\n",
       "        [ 62],\n",
       "        [ 54],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  3],\n",
       "        [  4],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  3]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  6],\n",
       "        [  0],\n",
       "        [102],\n",
       "        [204],\n",
       "        [176],\n",
       "        [134],\n",
       "        [144],\n",
       "        [123],\n",
       "        [ 23],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 12],\n",
       "        [ 10],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [155],\n",
       "        [236],\n",
       "        [207],\n",
       "        [178],\n",
       "        [107],\n",
       "        [156],\n",
       "        [161],\n",
       "        [109],\n",
       "        [ 64],\n",
       "        [ 23],\n",
       "        [ 77],\n",
       "        [130],\n",
       "        [ 72],\n",
       "        [ 15]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  0],\n",
       "        [ 69],\n",
       "        [207],\n",
       "        [223],\n",
       "        [218],\n",
       "        [216],\n",
       "        [216],\n",
       "        [163],\n",
       "        [127],\n",
       "        [121],\n",
       "        [122],\n",
       "        [146],\n",
       "        [141],\n",
       "        [ 88],\n",
       "        [172],\n",
       "        [ 66]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  1],\n",
       "        [  1],\n",
       "        [  0],\n",
       "        [200],\n",
       "        [232],\n",
       "        [232],\n",
       "        [233],\n",
       "        [229],\n",
       "        [223],\n",
       "        [223],\n",
       "        [215],\n",
       "        [213],\n",
       "        [164],\n",
       "        [127],\n",
       "        [123],\n",
       "        [196],\n",
       "        [229],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [183],\n",
       "        [225],\n",
       "        [216],\n",
       "        [223],\n",
       "        [228],\n",
       "        [235],\n",
       "        [227],\n",
       "        [224],\n",
       "        [222],\n",
       "        [224],\n",
       "        [221],\n",
       "        [223],\n",
       "        [245],\n",
       "        [173],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [193],\n",
       "        [228],\n",
       "        [218],\n",
       "        [213],\n",
       "        [198],\n",
       "        [180],\n",
       "        [212],\n",
       "        [210],\n",
       "        [211],\n",
       "        [213],\n",
       "        [223],\n",
       "        [220],\n",
       "        [243],\n",
       "        [202],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  3],\n",
       "        [  0],\n",
       "        [ 12],\n",
       "        [219],\n",
       "        [220],\n",
       "        [212],\n",
       "        [218],\n",
       "        [192],\n",
       "        [169],\n",
       "        [227],\n",
       "        [208],\n",
       "        [218],\n",
       "        [224],\n",
       "        [212],\n",
       "        [226],\n",
       "        [197],\n",
       "        [209],\n",
       "        [ 52]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  6],\n",
       "        [  0],\n",
       "        [ 99],\n",
       "        [244],\n",
       "        [222],\n",
       "        [220],\n",
       "        [218],\n",
       "        [203],\n",
       "        [198],\n",
       "        [221],\n",
       "        [215],\n",
       "        [213],\n",
       "        [222],\n",
       "        [220],\n",
       "        [245],\n",
       "        [119],\n",
       "        [167],\n",
       "        [ 56]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  4],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 55],\n",
       "        [236],\n",
       "        [228],\n",
       "        [230],\n",
       "        [228],\n",
       "        [240],\n",
       "        [232],\n",
       "        [213],\n",
       "        [218],\n",
       "        [223],\n",
       "        [234],\n",
       "        [217],\n",
       "        [217],\n",
       "        [209],\n",
       "        [ 92],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  4],\n",
       "        [  6],\n",
       "        [  7],\n",
       "        [  2],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [237],\n",
       "        [226],\n",
       "        [217],\n",
       "        [223],\n",
       "        [222],\n",
       "        [219],\n",
       "        [222],\n",
       "        [221],\n",
       "        [216],\n",
       "        [223],\n",
       "        [229],\n",
       "        [215],\n",
       "        [218],\n",
       "        [255],\n",
       "        [ 77],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  3],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 62],\n",
       "        [145],\n",
       "        [204],\n",
       "        [228],\n",
       "        [207],\n",
       "        [213],\n",
       "        [221],\n",
       "        [218],\n",
       "        [208],\n",
       "        [211],\n",
       "        [218],\n",
       "        [224],\n",
       "        [223],\n",
       "        [219],\n",
       "        [215],\n",
       "        [224],\n",
       "        [244],\n",
       "        [159],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 18],\n",
       "        [ 44],\n",
       "        [ 82],\n",
       "        [107],\n",
       "        [189],\n",
       "        [228],\n",
       "        [220],\n",
       "        [222],\n",
       "        [217],\n",
       "        [226],\n",
       "        [200],\n",
       "        [205],\n",
       "        [211],\n",
       "        [230],\n",
       "        [224],\n",
       "        [234],\n",
       "        [176],\n",
       "        [188],\n",
       "        [250],\n",
       "        [248],\n",
       "        [233],\n",
       "        [238],\n",
       "        [215],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [ 57],\n",
       "        [187],\n",
       "        [208],\n",
       "        [224],\n",
       "        [221],\n",
       "        [224],\n",
       "        [208],\n",
       "        [204],\n",
       "        [214],\n",
       "        [208],\n",
       "        [209],\n",
       "        [200],\n",
       "        [159],\n",
       "        [245],\n",
       "        [193],\n",
       "        [206],\n",
       "        [223],\n",
       "        [255],\n",
       "        [255],\n",
       "        [221],\n",
       "        [234],\n",
       "        [221],\n",
       "        [211],\n",
       "        [220],\n",
       "        [232],\n",
       "        [246],\n",
       "        [  0]],\n",
       "\n",
       "       [[  3],\n",
       "        [202],\n",
       "        [228],\n",
       "        [224],\n",
       "        [221],\n",
       "        [211],\n",
       "        [211],\n",
       "        [214],\n",
       "        [205],\n",
       "        [205],\n",
       "        [205],\n",
       "        [220],\n",
       "        [240],\n",
       "        [ 80],\n",
       "        [150],\n",
       "        [255],\n",
       "        [229],\n",
       "        [221],\n",
       "        [188],\n",
       "        [154],\n",
       "        [191],\n",
       "        [210],\n",
       "        [204],\n",
       "        [209],\n",
       "        [222],\n",
       "        [228],\n",
       "        [225],\n",
       "        [  0]],\n",
       "\n",
       "       [[ 98],\n",
       "        [233],\n",
       "        [198],\n",
       "        [210],\n",
       "        [222],\n",
       "        [229],\n",
       "        [229],\n",
       "        [234],\n",
       "        [249],\n",
       "        [220],\n",
       "        [194],\n",
       "        [215],\n",
       "        [217],\n",
       "        [241],\n",
       "        [ 65],\n",
       "        [ 73],\n",
       "        [106],\n",
       "        [117],\n",
       "        [168],\n",
       "        [219],\n",
       "        [221],\n",
       "        [215],\n",
       "        [217],\n",
       "        [223],\n",
       "        [223],\n",
       "        [224],\n",
       "        [229],\n",
       "        [ 29]],\n",
       "\n",
       "       [[ 75],\n",
       "        [204],\n",
       "        [212],\n",
       "        [204],\n",
       "        [193],\n",
       "        [205],\n",
       "        [211],\n",
       "        [225],\n",
       "        [216],\n",
       "        [185],\n",
       "        [197],\n",
       "        [206],\n",
       "        [198],\n",
       "        [213],\n",
       "        [240],\n",
       "        [195],\n",
       "        [227],\n",
       "        [245],\n",
       "        [239],\n",
       "        [223],\n",
       "        [218],\n",
       "        [212],\n",
       "        [209],\n",
       "        [222],\n",
       "        [220],\n",
       "        [221],\n",
       "        [230],\n",
       "        [ 67]],\n",
       "\n",
       "       [[ 48],\n",
       "        [203],\n",
       "        [183],\n",
       "        [194],\n",
       "        [213],\n",
       "        [197],\n",
       "        [185],\n",
       "        [190],\n",
       "        [194],\n",
       "        [192],\n",
       "        [202],\n",
       "        [214],\n",
       "        [219],\n",
       "        [221],\n",
       "        [220],\n",
       "        [236],\n",
       "        [225],\n",
       "        [216],\n",
       "        [199],\n",
       "        [206],\n",
       "        [186],\n",
       "        [181],\n",
       "        [177],\n",
       "        [172],\n",
       "        [181],\n",
       "        [205],\n",
       "        [206],\n",
       "        [115]],\n",
       "\n",
       "       [[  0],\n",
       "        [122],\n",
       "        [219],\n",
       "        [193],\n",
       "        [179],\n",
       "        [171],\n",
       "        [183],\n",
       "        [196],\n",
       "        [204],\n",
       "        [210],\n",
       "        [213],\n",
       "        [207],\n",
       "        [211],\n",
       "        [210],\n",
       "        [200],\n",
       "        [196],\n",
       "        [194],\n",
       "        [191],\n",
       "        [195],\n",
       "        [191],\n",
       "        [198],\n",
       "        [192],\n",
       "        [176],\n",
       "        [156],\n",
       "        [167],\n",
       "        [177],\n",
       "        [210],\n",
       "        [ 92]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [ 74],\n",
       "        [189],\n",
       "        [212],\n",
       "        [191],\n",
       "        [175],\n",
       "        [172],\n",
       "        [175],\n",
       "        [181],\n",
       "        [185],\n",
       "        [188],\n",
       "        [189],\n",
       "        [188],\n",
       "        [193],\n",
       "        [198],\n",
       "        [204],\n",
       "        [209],\n",
       "        [210],\n",
       "        [210],\n",
       "        [211],\n",
       "        [188],\n",
       "        [188],\n",
       "        [194],\n",
       "        [192],\n",
       "        [216],\n",
       "        [170],\n",
       "        [  0]],\n",
       "\n",
       "       [[  2],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 66],\n",
       "        [200],\n",
       "        [222],\n",
       "        [237],\n",
       "        [239],\n",
       "        [242],\n",
       "        [246],\n",
       "        [243],\n",
       "        [244],\n",
       "        [221],\n",
       "        [220],\n",
       "        [193],\n",
       "        [191],\n",
       "        [179],\n",
       "        [182],\n",
       "        [182],\n",
       "        [181],\n",
       "        [176],\n",
       "        [166],\n",
       "        [168],\n",
       "        [ 99],\n",
       "        [ 58],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 40],\n",
       "        [ 61],\n",
       "        [ 44],\n",
       "        [ 72],\n",
       "        [ 41],\n",
       "        [ 35],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fgq-DPpDY0y"
   },
   "source": [
    "## What is the min/max for this image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1674731930836,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "Zk9fC6JDDUp3",
    "outputId": "ecaa2025-b358-40a4-943a-49824afeb843"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1674731931540,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "ciTWCBVjDXL3",
    "outputId": "64ba7a41-911d-4c68-de5a-1010da36c740"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BykRwF2UmP8b"
   },
   "source": [
    "## Normalise\n",
    "\n",
    "We need to normalise the data since the values range from 0 to 255. Training NNs on data ranging between [0,1] is recommended.\n",
    "\n",
    "Need to normalise all features, including training, validation and testing. We also need to apply the same normalisation to any new data (obtained in the future)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1674732008449,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "FH2lcHF3mP8c"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXCZiTPZDB3d"
   },
   "source": [
    "## Take a look at a single image (after normalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 796,
     "status": "ok",
     "timestamp": 1674732062208,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "nRTTJ4kDDB_s",
    "outputId": "b3cc6319-28a7-4148-d843-730734c61671"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.05098039],\n",
       "        [0.28627451],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01568627],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.14117647],\n",
       "        [0.53333333],\n",
       "        [0.49803922],\n",
       "        [0.24313725],\n",
       "        [0.21176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.01568627],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.        ],\n",
       "        [0.4       ],\n",
       "        [0.8       ],\n",
       "        [0.69019608],\n",
       "        [0.5254902 ],\n",
       "        [0.56470588],\n",
       "        [0.48235294],\n",
       "        [0.09019608],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.03921569],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.60784314],\n",
       "        [0.9254902 ],\n",
       "        [0.81176471],\n",
       "        [0.69803922],\n",
       "        [0.41960784],\n",
       "        [0.61176471],\n",
       "        [0.63137255],\n",
       "        [0.42745098],\n",
       "        [0.25098039],\n",
       "        [0.09019608],\n",
       "        [0.30196078],\n",
       "        [0.50980392],\n",
       "        [0.28235294],\n",
       "        [0.05882353]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.27058824],\n",
       "        [0.81176471],\n",
       "        [0.8745098 ],\n",
       "        [0.85490196],\n",
       "        [0.84705882],\n",
       "        [0.84705882],\n",
       "        [0.63921569],\n",
       "        [0.49803922],\n",
       "        [0.4745098 ],\n",
       "        [0.47843137],\n",
       "        [0.57254902],\n",
       "        [0.55294118],\n",
       "        [0.34509804],\n",
       "        [0.6745098 ],\n",
       "        [0.25882353]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.78431373],\n",
       "        [0.90980392],\n",
       "        [0.90980392],\n",
       "        [0.91372549],\n",
       "        [0.89803922],\n",
       "        [0.8745098 ],\n",
       "        [0.8745098 ],\n",
       "        [0.84313725],\n",
       "        [0.83529412],\n",
       "        [0.64313725],\n",
       "        [0.49803922],\n",
       "        [0.48235294],\n",
       "        [0.76862745],\n",
       "        [0.89803922],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.71764706],\n",
       "        [0.88235294],\n",
       "        [0.84705882],\n",
       "        [0.8745098 ],\n",
       "        [0.89411765],\n",
       "        [0.92156863],\n",
       "        [0.89019608],\n",
       "        [0.87843137],\n",
       "        [0.87058824],\n",
       "        [0.87843137],\n",
       "        [0.86666667],\n",
       "        [0.8745098 ],\n",
       "        [0.96078431],\n",
       "        [0.67843137],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.75686275],\n",
       "        [0.89411765],\n",
       "        [0.85490196],\n",
       "        [0.83529412],\n",
       "        [0.77647059],\n",
       "        [0.70588235],\n",
       "        [0.83137255],\n",
       "        [0.82352941],\n",
       "        [0.82745098],\n",
       "        [0.83529412],\n",
       "        [0.8745098 ],\n",
       "        [0.8627451 ],\n",
       "        [0.95294118],\n",
       "        [0.79215686],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.85882353],\n",
       "        [0.8627451 ],\n",
       "        [0.83137255],\n",
       "        [0.85490196],\n",
       "        [0.75294118],\n",
       "        [0.6627451 ],\n",
       "        [0.89019608],\n",
       "        [0.81568627],\n",
       "        [0.85490196],\n",
       "        [0.87843137],\n",
       "        [0.83137255],\n",
       "        [0.88627451],\n",
       "        [0.77254902],\n",
       "        [0.81960784],\n",
       "        [0.20392157]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.        ],\n",
       "        [0.38823529],\n",
       "        [0.95686275],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.85490196],\n",
       "        [0.79607843],\n",
       "        [0.77647059],\n",
       "        [0.86666667],\n",
       "        [0.84313725],\n",
       "        [0.83529412],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.96078431],\n",
       "        [0.46666667],\n",
       "        [0.65490196],\n",
       "        [0.21960784]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01568627],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.21568627],\n",
       "        [0.9254902 ],\n",
       "        [0.89411765],\n",
       "        [0.90196078],\n",
       "        [0.89411765],\n",
       "        [0.94117647],\n",
       "        [0.90980392],\n",
       "        [0.83529412],\n",
       "        [0.85490196],\n",
       "        [0.8745098 ],\n",
       "        [0.91764706],\n",
       "        [0.85098039],\n",
       "        [0.85098039],\n",
       "        [0.81960784],\n",
       "        [0.36078431],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01568627],\n",
       "        [0.02352941],\n",
       "        [0.02745098],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.92941176],\n",
       "        [0.88627451],\n",
       "        [0.85098039],\n",
       "        [0.8745098 ],\n",
       "        [0.87058824],\n",
       "        [0.85882353],\n",
       "        [0.87058824],\n",
       "        [0.86666667],\n",
       "        [0.84705882],\n",
       "        [0.8745098 ],\n",
       "        [0.89803922],\n",
       "        [0.84313725],\n",
       "        [0.85490196],\n",
       "        [1.        ],\n",
       "        [0.30196078],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.24313725],\n",
       "        [0.56862745],\n",
       "        [0.8       ],\n",
       "        [0.89411765],\n",
       "        [0.81176471],\n",
       "        [0.83529412],\n",
       "        [0.86666667],\n",
       "        [0.85490196],\n",
       "        [0.81568627],\n",
       "        [0.82745098],\n",
       "        [0.85490196],\n",
       "        [0.87843137],\n",
       "        [0.8745098 ],\n",
       "        [0.85882353],\n",
       "        [0.84313725],\n",
       "        [0.87843137],\n",
       "        [0.95686275],\n",
       "        [0.62352941],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.17254902],\n",
       "        [0.32156863],\n",
       "        [0.41960784],\n",
       "        [0.74117647],\n",
       "        [0.89411765],\n",
       "        [0.8627451 ],\n",
       "        [0.87058824],\n",
       "        [0.85098039],\n",
       "        [0.88627451],\n",
       "        [0.78431373],\n",
       "        [0.80392157],\n",
       "        [0.82745098],\n",
       "        [0.90196078],\n",
       "        [0.87843137],\n",
       "        [0.91764706],\n",
       "        [0.69019608],\n",
       "        [0.7372549 ],\n",
       "        [0.98039216],\n",
       "        [0.97254902],\n",
       "        [0.91372549],\n",
       "        [0.93333333],\n",
       "        [0.84313725],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.22352941],\n",
       "        [0.73333333],\n",
       "        [0.81568627],\n",
       "        [0.87843137],\n",
       "        [0.86666667],\n",
       "        [0.87843137],\n",
       "        [0.81568627],\n",
       "        [0.8       ],\n",
       "        [0.83921569],\n",
       "        [0.81568627],\n",
       "        [0.81960784],\n",
       "        [0.78431373],\n",
       "        [0.62352941],\n",
       "        [0.96078431],\n",
       "        [0.75686275],\n",
       "        [0.80784314],\n",
       "        [0.8745098 ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.86666667],\n",
       "        [0.91764706],\n",
       "        [0.86666667],\n",
       "        [0.82745098],\n",
       "        [0.8627451 ],\n",
       "        [0.90980392],\n",
       "        [0.96470588],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.01176471],\n",
       "        [0.79215686],\n",
       "        [0.89411765],\n",
       "        [0.87843137],\n",
       "        [0.86666667],\n",
       "        [0.82745098],\n",
       "        [0.82745098],\n",
       "        [0.83921569],\n",
       "        [0.80392157],\n",
       "        [0.80392157],\n",
       "        [0.80392157],\n",
       "        [0.8627451 ],\n",
       "        [0.94117647],\n",
       "        [0.31372549],\n",
       "        [0.58823529],\n",
       "        [1.        ],\n",
       "        [0.89803922],\n",
       "        [0.86666667],\n",
       "        [0.7372549 ],\n",
       "        [0.60392157],\n",
       "        [0.74901961],\n",
       "        [0.82352941],\n",
       "        [0.8       ],\n",
       "        [0.81960784],\n",
       "        [0.87058824],\n",
       "        [0.89411765],\n",
       "        [0.88235294],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.38431373],\n",
       "        [0.91372549],\n",
       "        [0.77647059],\n",
       "        [0.82352941],\n",
       "        [0.87058824],\n",
       "        [0.89803922],\n",
       "        [0.89803922],\n",
       "        [0.91764706],\n",
       "        [0.97647059],\n",
       "        [0.8627451 ],\n",
       "        [0.76078431],\n",
       "        [0.84313725],\n",
       "        [0.85098039],\n",
       "        [0.94509804],\n",
       "        [0.25490196],\n",
       "        [0.28627451],\n",
       "        [0.41568627],\n",
       "        [0.45882353],\n",
       "        [0.65882353],\n",
       "        [0.85882353],\n",
       "        [0.86666667],\n",
       "        [0.84313725],\n",
       "        [0.85098039],\n",
       "        [0.8745098 ],\n",
       "        [0.8745098 ],\n",
       "        [0.87843137],\n",
       "        [0.89803922],\n",
       "        [0.11372549]],\n",
       "\n",
       "       [[0.29411765],\n",
       "        [0.8       ],\n",
       "        [0.83137255],\n",
       "        [0.8       ],\n",
       "        [0.75686275],\n",
       "        [0.80392157],\n",
       "        [0.82745098],\n",
       "        [0.88235294],\n",
       "        [0.84705882],\n",
       "        [0.7254902 ],\n",
       "        [0.77254902],\n",
       "        [0.80784314],\n",
       "        [0.77647059],\n",
       "        [0.83529412],\n",
       "        [0.94117647],\n",
       "        [0.76470588],\n",
       "        [0.89019608],\n",
       "        [0.96078431],\n",
       "        [0.9372549 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85490196],\n",
       "        [0.83137255],\n",
       "        [0.81960784],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.86666667],\n",
       "        [0.90196078],\n",
       "        [0.2627451 ]],\n",
       "\n",
       "       [[0.18823529],\n",
       "        [0.79607843],\n",
       "        [0.71764706],\n",
       "        [0.76078431],\n",
       "        [0.83529412],\n",
       "        [0.77254902],\n",
       "        [0.7254902 ],\n",
       "        [0.74509804],\n",
       "        [0.76078431],\n",
       "        [0.75294118],\n",
       "        [0.79215686],\n",
       "        [0.83921569],\n",
       "        [0.85882353],\n",
       "        [0.86666667],\n",
       "        [0.8627451 ],\n",
       "        [0.9254902 ],\n",
       "        [0.88235294],\n",
       "        [0.84705882],\n",
       "        [0.78039216],\n",
       "        [0.80784314],\n",
       "        [0.72941176],\n",
       "        [0.70980392],\n",
       "        [0.69411765],\n",
       "        [0.6745098 ],\n",
       "        [0.70980392],\n",
       "        [0.80392157],\n",
       "        [0.80784314],\n",
       "        [0.45098039]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.47843137],\n",
       "        [0.85882353],\n",
       "        [0.75686275],\n",
       "        [0.70196078],\n",
       "        [0.67058824],\n",
       "        [0.71764706],\n",
       "        [0.76862745],\n",
       "        [0.8       ],\n",
       "        [0.82352941],\n",
       "        [0.83529412],\n",
       "        [0.81176471],\n",
       "        [0.82745098],\n",
       "        [0.82352941],\n",
       "        [0.78431373],\n",
       "        [0.76862745],\n",
       "        [0.76078431],\n",
       "        [0.74901961],\n",
       "        [0.76470588],\n",
       "        [0.74901961],\n",
       "        [0.77647059],\n",
       "        [0.75294118],\n",
       "        [0.69019608],\n",
       "        [0.61176471],\n",
       "        [0.65490196],\n",
       "        [0.69411765],\n",
       "        [0.82352941],\n",
       "        [0.36078431]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.29019608],\n",
       "        [0.74117647],\n",
       "        [0.83137255],\n",
       "        [0.74901961],\n",
       "        [0.68627451],\n",
       "        [0.6745098 ],\n",
       "        [0.68627451],\n",
       "        [0.70980392],\n",
       "        [0.7254902 ],\n",
       "        [0.7372549 ],\n",
       "        [0.74117647],\n",
       "        [0.7372549 ],\n",
       "        [0.75686275],\n",
       "        [0.77647059],\n",
       "        [0.8       ],\n",
       "        [0.81960784],\n",
       "        [0.82352941],\n",
       "        [0.82352941],\n",
       "        [0.82745098],\n",
       "        [0.7372549 ],\n",
       "        [0.7372549 ],\n",
       "        [0.76078431],\n",
       "        [0.75294118],\n",
       "        [0.84705882],\n",
       "        [0.66666667],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.25882353],\n",
       "        [0.78431373],\n",
       "        [0.87058824],\n",
       "        [0.92941176],\n",
       "        [0.9372549 ],\n",
       "        [0.94901961],\n",
       "        [0.96470588],\n",
       "        [0.95294118],\n",
       "        [0.95686275],\n",
       "        [0.86666667],\n",
       "        [0.8627451 ],\n",
       "        [0.75686275],\n",
       "        [0.74901961],\n",
       "        [0.70196078],\n",
       "        [0.71372549],\n",
       "        [0.71372549],\n",
       "        [0.70980392],\n",
       "        [0.69019608],\n",
       "        [0.65098039],\n",
       "        [0.65882353],\n",
       "        [0.38823529],\n",
       "        [0.22745098],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15686275],\n",
       "        [0.23921569],\n",
       "        [0.17254902],\n",
       "        [0.28235294],\n",
       "        [0.16078431],\n",
       "        [0.1372549 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzew90mNDdoJ"
   },
   "source": [
    "## What is the min/max for this image after normalisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1674732071835,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "VzGZPbxvDdoO",
    "outputId": "5e294842-d26a-45c9-a439-38ded334d690"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1674732071836,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "gGkND0LVDdoS",
    "outputId": "0ff0438c-2539-4bfd-9ff1-7ec4f4cd05ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kj0QhPSsmP8e"
   },
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGRXrRTYmP8g"
   },
   "source": [
    "## Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1674732074208,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "wrKyI7DamP8g",
    "outputId": "60331221-71cd-47cb-c83e-7fa829d990a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfClFp-6K7P6"
   },
   "source": [
    "## Convert from categorical labels to one-hot encoded vectors\n",
    "\n",
    "In this case there are 10 classes so we can tell the function to convert into a vector of length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1674732075201,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "i3xjsPnVmP8j"
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92H9U6LkmP8m"
   },
   "source": [
    "## After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1674732092415,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "tiiXZrnUmP8n",
    "outputId": "9a372834-f2b0-4494-d9fa-48ecf58b6574"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VungsdeHmP8u"
   },
   "source": [
    "## Create a CNN model\n",
    "\n",
    "A lot of things here are not new. \n",
    "\n",
    "Creating a sequential model is not new.\n",
    "\n",
    "Dropout is not new\n",
    "\n",
    "Creating a fully connected layer is not new.\n",
    "\n",
    "Creating a softmax output is not new.\n",
    "\n",
    "What's new is: Conv2D, MaxPooling2D and Flatten\n",
    "\n",
    "Documentation:\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePJ69ZjywxHe"
   },
   "source": [
    "## Building the CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjKcodEQwxHe"
   },
   "source": [
    "* On the first layer, we need to specify the `input shape`. Only here, only once. There below, we are creating 64 filters each of size 2x2. What will be the depth of each of those 64 filters? What will be the resulting depth of the feature map after applying these filters?\n",
    "\n",
    "\n",
    "*  \tone of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. When padding=\"same\" and strides=1, the output has the same size as the input.\n",
    "\n",
    "\n",
    "* Here we create a 2x2 max pooling layer\n",
    "\n",
    "\n",
    "* In order to pass output from the convolutional block to the dense block, we must flatten each example  in the minibatch. In other words, we take this four-dimensional input [batch, width, height, depth] and transform it  into the two-dimensional input [batch, units/input dimensions] expected by fully-connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1674732228268,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "ViAjlskkwxHe"
   },
   "outputs": [],
   "source": [
    "Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1674732587469,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "gozmsPxhmP8v"
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "   \n",
    "    model.add(Conv2D(filters=64, kernel_size=2,  padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "    \n",
    "    \n",
    "    model.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    optimizer = SGD(learning_rate=0.9)\n",
    "    loss = CategoricalCrossentropy()\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss=loss,\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 3948,
     "status": "ok",
     "timestamp": 1674732601268,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "Q03EcUrxmP8x"
   },
   "outputs": [],
   "source": [
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUN6K31smP80"
   },
   "source": [
    "## Determine the number of trainable parameters\n",
    "\n",
    "Look at how many parameters we get from the last layer in the feature extractor to the first fully connected layer in the classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1343,
     "status": "ok",
     "timestamp": 1674732604437,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "_DxDanOHmP80",
    "outputId": "0e1d3932-9184-401d-8d4a-d929c39331ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                802880    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805,610\n",
      "Trainable params: 805,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppxTtRIfBUgr"
   },
   "source": [
    "Now let's do something new. Let's save the model weights while training and keep track of the best model on the validation accuracy.\n",
    "\n",
    "API for saving checkpoints https://www.tensorflow.org/tutorials/keras/save_and_load and https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "\n",
    "Additional things like the ability to determine the latest checkpoint exists: `tf.train.latest_checkpoint`. Take a look at the documentation for more interesting things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1674732657590,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "HBQfomgaBUo3"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                              save_best_only=True, \n",
    "                              save_weights_only=True, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifPs0mftmP84"
   },
   "source": [
    "## Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27505,
     "status": "ok",
     "timestamp": 1674732721956,
     "user": {
      "displayName": "Rockefeller",
      "userId": "14247310336372995288"
     },
     "user_tz": -60
    },
    "id": "j8RZc1rhmP84",
    "outputId": "d1eccd45-6057-4c6c-f862-1e9094709439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "234/235 [============================>.] - ETA: 0s - loss: 1.4627 - accuracy: 0.4287\n",
      "Epoch 1: val_loss improved from inf to 0.67374, saving model to training/cp-0001.ckpt\n",
      "235/235 [==============================] - 10s 9ms/step - loss: 1.4617 - accuracy: 0.4291 - val_loss: 0.6737 - val_accuracy: 0.7546\n",
      "Epoch 2/10\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.7568 - accuracy: 0.7230\n",
      "Epoch 2: val_loss improved from 0.67374 to 0.50093, saving model to training/cp-0002.ckpt\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.7557 - accuracy: 0.7233 - val_loss: 0.5009 - val_accuracy: 0.8333\n",
      "Epoch 3/10\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.6610 - accuracy: 0.7655\n",
      "Epoch 3: val_loss improved from 0.50093 to 0.47801, saving model to training/cp-0003.ckpt\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.6605 - accuracy: 0.7656 - val_loss: 0.4780 - val_accuracy: 0.8259\n",
      "Epoch 4/10\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.6280 - accuracy: 0.7805\n",
      "Epoch 4: val_loss did not improve from 0.47801\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.6274 - accuracy: 0.7807 - val_loss: 0.5039 - val_accuracy: 0.8295\n",
      "Epoch 5/10\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.6057 - accuracy: 0.7907\n",
      "Epoch 5: val_loss did not improve from 0.47801\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.6060 - accuracy: 0.7907 - val_loss: 0.4878 - val_accuracy: 0.8222\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.5914 - accuracy: 0.7968\n",
      "Epoch 6: val_loss improved from 0.47801 to 0.43666, saving model to training/cp-0006.ckpt\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.5914 - accuracy: 0.7968 - val_loss: 0.4367 - val_accuracy: 0.8436\n",
      "Epoch 7/10\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.5700 - accuracy: 0.8037\n",
      "Epoch 7: val_loss did not improve from 0.43666\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.5699 - accuracy: 0.8037 - val_loss: 0.4582 - val_accuracy: 0.8293\n",
      "Epoch 8/10\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.5488 - accuracy: 0.8100\n",
      "Epoch 8: val_loss did not improve from 0.43666\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.5491 - accuracy: 0.8097 - val_loss: 0.4893 - val_accuracy: 0.8486\n",
      "Epoch 9/10\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.5409 - accuracy: 0.8127\n",
      "Epoch 9: val_loss improved from 0.43666 to 0.40588, saving model to training/cp-0009.ckpt\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.5396 - accuracy: 0.8130 - val_loss: 0.4059 - val_accuracy: 0.8608\n",
      "Epoch 10/10\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.5273 - accuracy: 0.8169\n",
      "Epoch 10: val_loss improved from 0.40588 to 0.39957, saving model to training/cp-0010.ckpt\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.5270 - accuracy: 0.8171 - val_loss: 0.3996 - val_accuracy: 0.8557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd5146cd610>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=256, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KRrCPwmCtkP"
   },
   "source": [
    "Check on the left using the `file` option. You'll see a new folder and the checkpoints saved. Next let's get the correct testing values and then compare the predictions on the test data when initialising the model as opposed to loading the best weights from training and predicting again on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taRru5jrHm8P"
   },
   "outputs": [],
   "source": [
    "correct_values = np.argmax(Y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Glts9LxlHeF_"
   },
   "outputs": [],
   "source": [
    "model = baseline_model()\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "accuracy_score(predictions,correct_values)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQHPH-eIgRTM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YrYa0jqFCtuO"
   },
   "outputs": [],
   "source": [
    "model = baseline_model()\n",
    "model.load_weights(\"training/cp-0010.ckpt\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "accuracy_score(predictions,correct_values)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9do3Cl8vmP87"
   },
   "source": [
    "## Predict on one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnI4SnbEmP88"
   },
   "outputs": [],
   "source": [
    "model.predict(np.expand_dims(X_test[0], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yW3HNzapEV47"
   },
   "source": [
    "## Predicting, but obtaining the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80LVXvFkEWEY"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(np.expand_dims(X_test[0], axis=0))\n",
    "np.argmax(prediction, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_j9LecHgmP8_"
   },
   "source": [
    "## Predict on all the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TtfkDWjmP8_"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBmZspLUmP9C"
   },
   "outputs": [],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKy0gGBhE2gX"
   },
   "source": [
    "Before applying the `accuracy_score` function we need to conver the data into single class integers. In it's current form, the Y_test values aren't suitable. To address this, we can use the `np.argmax` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJiTOY3aWjcX"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(predictions,correct_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEdkE4j--VzR"
   },
   "source": [
    "# Task:\n",
    "\n",
    "1) Add another convolutional layer to the current model.\n",
    "\n",
    "2) Add another max pooling layer to the current model.\n",
    "\n",
    "3) Modify the network and try improve your performance by using different architectures and hyper-parameters.\n",
    "\n",
    "4) Replace the max pooling with average pooling\n",
    "\n",
    "5) Add a stride of 2 to your average pooling layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSKtAYriFQLO"
   },
   "source": [
    "# References:\n",
    "\n",
    "* This notebook was adpated from Dr. Emmanuel Dufourq,  2021 Gene Golub SIAM Summer School "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIyXPHxkwxHg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
